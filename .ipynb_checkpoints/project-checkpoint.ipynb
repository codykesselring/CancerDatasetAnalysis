{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b2969",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import mysklearn.mypytable\n",
    "import importlib\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable\n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyNaiveBayesClassifier, MyRandomForestClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd375d",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2189d7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cancer_table = MyPyTable()\n",
    "cancer_table.load_from_file('input_data/cancer.csv')\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "or row in cancer_table.data:\n",
    "    # Skip if row is header or empty\n",
    "    if row[1] in ['M', 'B']: \n",
    "        features = []\n",
    "        radius = float(row[2])\n",
    "        if radius < 12:\n",
    "            features.append(\"small\")\n",
    "        elif radius < 17:\n",
    "            features.append(\"medium\")\n",
    "        else:\n",
    "            features.append(\"large\")\n",
    "\n",
    "        texture = float(row[3])\n",
    "        if texture < 18:\n",
    "            features.append(\"smooth\")\n",
    "        elif texture < 22:\n",
    "            features.append(\"moderate\")\n",
    "        else:\n",
    "            features.append(\"rough\")\n",
    "\n",
    "        perimeter = float(row[4])\n",
    "        if perimeter < 85:\n",
    "            features.append(\"small_p\")\n",
    "        elif perimeter < 115:\n",
    "            features.append(\"medium_p\")\n",
    "        else:\n",
    "            features.append(\"large_p\")\n",
    "\n",
    "        X.append(features)\n",
    "        y.append(row[1])  # M or B\n",
    "\n",
    "print(f\"Loaded {len(X)} instances from cancer dataset\")\n",
    "print(f\"Sample X: {X[0]}, y: {y[0]}\")\n",
    "print(f\"Sample X: {X[1]}, y: {y[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f401577",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42aa9a1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "folds = myevaluation.kfold_split(X, n_splits=10, random_state=0, shuffle=True)\n",
    "\n",
    "nb_all_y_true = []\n",
    "nb_all_y_pred = []\n",
    "\n",
    "print(\"Running Naive Bayes with 10-fold cross-validation...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for fold_idx, (train_indices, test_indices) in enumerate(folds):\n",
    "    # Get train and test data for this fold\n",
    "    X_train = [X[i] for i in train_indices]\n",
    "    y_train = [y[i] for i in train_indices]\n",
    "    X_test = [X[i] for i in test_indices]\n",
    "    y_test = [y[i] for i in test_indices]\n",
    "\n",
    "    # Train Naive Bayes classifier\n",
    "    nb_clf = MyNaiveBayesClassifier()\n",
    "    nb_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = nb_clf.predict(X_test)\n",
    "\n",
    "    # Store results\n",
    "    nb_all_y_true.extend(y_test)\n",
    "    nb_all_y_pred.extend(y_pred)\n",
    "\n",
    "    # Calculate and print fold accuracy\n",
    "    fold_accuracy = myevaluation.accuracy_score(y_test, y_pred)\n",
    "    print(f\"Fold {fold_idx + 1}: Accuracy = {fold_accuracy:.4f}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate overall metrics\n",
    "nb_accuracy = myevaluation.accuracy_score(nb_all_y_true, nb_all_y_pred)\n",
    "nb_error_rate = 1 - nb_accuracy\n",
    "\n",
    "print(f\"\\nOverall Accuracy: {nb_accuracy:.4f}\")\n",
    "print(f\"Overall Error Rate: {nb_error_rate:.4f}\")\n",
    "\n",
    "labels = [\"B\", \"M\"]\n",
    "\n",
    "# Calculate precision, recall, and F1 score (using 'M' as positive class for cancer)\n",
    "nb_precision = myevaluation.binary_precision_score(nb_all_y_true, nb_all_y_pred,\n",
    "                                                     labels=labels, pos_label=\"M\")\n",
    "nb_recall = myevaluation.binary_recall_score(nb_all_y_true, nb_all_y_pred,\n",
    "                                               labels=labels, pos_label=\"M\")\n",
    "nb_f1 = myevaluation.binary_f1_score(nb_all_y_true, nb_all_y_pred,\n",
    "                                      labels=labels, pos_label=\"M\")\n",
    "\n",
    "print(f\"\\nPrecision (Malignant): {nb_precision:.4f}\")\n",
    "print(f\"Recall (Malignant): {nb_recall:.4f}\")\n",
    "print(f\"F1 Score (Malignant): {nb_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf92c88",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f715bff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rf_all_y_true = []\n",
    "rf_all_y_pred = []\n",
    "\n",
    "print(\"Running Random Forest with 10-fold cross-validation...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for fold_idx, (train_indices, test_indices) in enumerate(folds):\n",
    "    # Get train and test data for this fold\n",
    "    X_train = [X[i] for i in train_indices]\n",
    "    y_train = [y[i] for i in train_indices]\n",
    "    X_test = [X[i] for i in test_indices]\n",
    "    y_test = [y[i] for i in test_indices]\n",
    "\n",
    "    # Train Random Forest classifier\n",
    "    # Using n_trees=20, m_trees=7, f_attributes=2 (defaults)\n",
    "    rf_clf = MyRandomForestClassifier(n_trees=20, m_trees=7, f_attributes=2, random_state=0)\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "    # Store results\n",
    "    rf_all_y_true.extend(y_test)\n",
    "    rf_all_y_pred.extend(y_pred)\n",
    "\n",
    "    # Calculate and print fold accuracy\n",
    "    fold_accuracy = myevaluation.accuracy_score(y_test, y_pred)\n",
    "    print(f\"Fold {fold_idx + 1}: Accuracy = {fold_accuracy:.4f}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate overall metrics for Random Forest\n",
    "rf_accuracy = myevaluation.accuracy_score(rf_all_y_true, rf_all_y_pred)\n",
    "rf_error_rate = 1 - rf_accuracy\n",
    "\n",
    "print(f\"\\nOverall Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Overall Error Rate: {rf_error_rate:.4f}\")\n",
    "\n",
    "# Calculate precision, recall, and F1 score for Random Forest\n",
    "rf_precision = myevaluation.binary_precision_score(rf_all_y_true, rf_all_y_pred,\n",
    "                                                     labels=labels, pos_label=\"M\")\n",
    "rf_recall = myevaluation.binary_recall_score(rf_all_y_true, rf_all_y_pred,\n",
    "                                               labels=labels, pos_label=\"M\")\n",
    "rf_f1 = myevaluation.binary_f1_score(rf_all_y_true, rf_all_y_pred,\n",
    "                                      labels=labels, pos_label=\"M\")\n",
    "\n",
    "print(f\"\\nPrecision (Malignant): {rf_precision:.4f}\")\n",
    "print(f\"Recall (Malignant): {rf_recall:.4f}\")\n",
    "print(f\"F1 Score (Malignant): {rf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f509b1a",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e8600",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dt_all_y_true = []\n",
    "dt_all_y_pred = []\n",
    "\n",
    "print(\"Running Decision Tree with 10-fold cross-validation...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for fold_idx, (train_indices, test_indices) in enumerate(folds):\n",
    "    # Get train and test data for this fold\n",
    "    X_train = [X[i] for i in train_indices]\n",
    "    y_train = [y[i] for i in train_indices]\n",
    "    X_test = [X[i] for i in test_indices]\n",
    "    y_test = [y[i] for i in test_indices]\n",
    "\n",
    "    # Train Decision Tree classifier\n",
    "    dt_clf = MyDecisionTreeClassifier()\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = dt_clf.predict(X_test)\n",
    "\n",
    "    # Store results\n",
    "    dt_all_y_true.extend(y_test)\n",
    "    dt_all_y_pred.extend(y_pred)\n",
    "\n",
    "    # Calculate and print fold accuracy\n",
    "    fold_accuracy = myevaluation.accuracy_score(y_test, y_pred)\n",
    "    print(f\"Fold {fold_idx + 1}: Accuracy = {fold_accuracy:.4f}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate overall metrics for Decision Tree\n",
    "dt_accuracy = myevaluation.accuracy_score(dt_all_y_true, dt_all_y_pred)\n",
    "dt_error_rate = 1 - dt_accuracy\n",
    "\n",
    "print(f\"\\nOverall Accuracy: {dt_accuracy:.4f}\")\n",
    "print(f\"Overall Error Rate: {dt_error_rate:.4f}\")\n",
    "\n",
    "# Calculate precision, recall, and F1 score for Decision Tree\n",
    "dt_precision = myevaluation.binary_precision_score(dt_all_y_true, dt_all_y_pred,\n",
    "                                                     labels=labels, pos_label=\"M\")\n",
    "dt_recall = myevaluation.binary_recall_score(dt_all_y_true, dt_all_y_pred,\n",
    "                                               labels=labels, pos_label=\"M\")\n",
    "dt_f1 = myevaluation.binary_f1_score(dt_all_y_true, dt_all_y_pred,\n",
    "                                      labels=labels, pos_label=\"M\")\n",
    "\n",
    "print(f\"\\nPrecision (Malignant): {dt_precision:.4f}\")\n",
    "print(f\"Recall (Malignant): {dt_recall:.4f}\")\n",
    "print(f\"F1 Score (Malignant): {dt_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1042f2c",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de21d1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dt_confusion_matrix = myevaluation.confusion_matrix(dt_all_y_true, dt_all_y_pred, labels)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"{'':12} {'Predicted B':>15} {'Predicted M':>15}\")\n",
    "print(f\"{'Actual B':12} {dt_confusion_matrix[0][0]:>15} {dt_confusion_matrix[0][1]:>15}\")\n",
    "print(f\"{'Actual M':12} {dt_confusion_matrix[1][0]:>15} {dt_confusion_matrix[1][1]:>15}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Comparison Summary\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFIER COMPARISON SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Metric':<25} {'Naive Bayes':>15} {'Random Forest':>15} {'Decision Tree':>15}\")\n",
    "print(\"-\"*75)\n",
    "print(f\"{'Accuracy':<25} {nb_accuracy:>15.4f} {rf_accuracy:>15.4f} {dt_accuracy:>15.4f}\")\n",
    "print(f\"{'Error Rate':<25} {nb_error_rate:>15.4f} {rf_error_rate:>15.4f} {dt_error_rate:>15.4f}\")\n",
    "print(f\"{'Precision (Malignant)':<25} {nb_precision:>15.4f} {rf_precision:>15.4f} {dt_precision:>15.4f}\")\n",
    "print(f\"{'Recall (Malignant)':<25} {nb_recall:>15.4f} {rf_recall:>15.4f} {dt_recall:>15.4f}\")\n",
    "print(f\"{'F1 Score (Malignant)':<25} {nb_f1:>15.4f} {rf_f1:>15.4f} {dt_f1:>15.4f}\")\n",
    "print(\"=\"*75)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
